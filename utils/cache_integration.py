"""
ç¼“å­˜é›†æˆæ¨¡å—
åœ¨å„ä¸ªå¤„ç†é˜¶æ®µé›†æˆç¼“å­˜åŠŸèƒ½ï¼Œæä¾›ç¼“å­˜æ£€æŸ¥ã€ä¿å­˜å’Œæ¢å¤åŠŸèƒ½
"""

from typing import Dict, Any, Optional, List, Tuple
from loguru import logger
from .cache_manager import get_cache_manager
from pathlib import Path
import streamlit as st
import time


class CacheIntegration:
    """ç¼“å­˜é›†æˆç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜é›†æˆ"""
        self.cache_manager = get_cache_manager()
    
    def check_srt_cache(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥SRTæ–‡ä»¶ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç¼“å­˜çš„SRTä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            cached_data = self.cache_manager.get_cache_entry(file_path, "srt_info")
            if cached_data:
                logger.info(f"æ‰¾åˆ°SRTä¿¡æ¯ç¼“å­˜: {Path(file_path).name}")
                return cached_data
            return None
        except Exception as e:
            logger.error(f"æ£€æŸ¥SRTç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def save_srt_cache(self, file_path: str, srt_info: Dict[str, Any]) -> bool:
        """
        ä¿å­˜SRTæ–‡ä»¶ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            srt_info: SRTæ–‡ä»¶ä¿¡æ¯
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            return self.cache_manager.set_cache_entry(file_path, "srt_info", srt_info)
        except Exception as e:
            logger.error(f"ä¿å­˜SRTç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def check_segmentation_cache(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥åˆ†æ®µä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç¼“å­˜çš„åˆ†æ®µä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            cached_data = self.cache_manager.get_cache_entry(file_path, "segmentation")
            if cached_data:
                logger.info(f"æ‰¾åˆ°åˆ†æ®µç¼“å­˜: {Path(file_path).name}")
                return cached_data
            return None
        except Exception as e:
            logger.error(f"æ£€æŸ¥åˆ†æ®µç¼“å­˜å¤±è´¥: {e}")
            return None

    def save_confirmed_segmentation_cache(self, file_path: str, confirmed_segments: List[Dict[str, Any]], original_segments: List[Dict[str, Any]]) -> bool:
        """
        ä¿å­˜ç”¨æˆ·ç¡®è®¤åçš„åˆ†æ®µä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            confirmed_segments: ç”¨æˆ·ç¡®è®¤åçš„åˆ†æ®µæ•°æ®
            original_segments: åŸå§‹ç‰‡æ®µæ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            # ä¿å­˜segmentationç¼“å­˜ï¼ˆåŒ…å«åŸå§‹å’Œç¡®è®¤æ•°æ®ï¼‰
            segmentation_data = {
                "original_segments": original_segments,
                "confirmed_segments": confirmed_segments,
                "confirmation_timestamp": time.time()
            }
            seg_result = self.cache_manager.set_cache_entry(file_path, "segmentation", segmentation_data)
            
            # åŒæ—¶ä¿å­˜confirmationç¼“å­˜ï¼ˆä»…åŒ…å«ç¡®è®¤æ•°æ®ï¼Œç”¨äºå¿«é€Ÿæ¢å¤ï¼‰
            confirmation_data = {
                "original_segments": original_segments,  # åŒæ—¶ä¿å­˜åŸå§‹åˆ†æ®µ
                "confirmed_segments": confirmed_segments,
                "confirmation_timestamp": time.time(),
                "cache_type": "segmentation_confirmation"
            }
            conf_result = self.cache_manager.set_cache_entry(file_path, "confirmation", confirmation_data)
            
            return seg_result and conf_result
        except Exception as e:
            logger.error(f"ä¿å­˜ç¡®è®¤åˆ†æ®µç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def check_translation_cache(self, file_path: str, target_lang: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥ç¿»è¯‘ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            ç¼“å­˜çš„ç¿»è¯‘ä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            # ä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·ç¡®è®¤åçš„ç¿»è¯‘ç¼“å­˜
            confirmed_cache = self.cache_manager.get_cache_entry(file_path, "translation_confirmed", target_lang=target_lang)
            if confirmed_cache:
                logger.info(f"æ‰¾åˆ°ç”¨æˆ·ç¡®è®¤åçš„ç¿»è¯‘ç¼“å­˜: {Path(file_path).name} -> {target_lang}")
                confirmed_cache['is_user_confirmed'] = True
                return confirmed_cache
            
            # å¦‚æœæ²¡æœ‰ç”¨æˆ·ç¡®è®¤çš„ç¼“å­˜ï¼Œåˆ™æ£€æŸ¥åˆæ¬¡ç¿»è¯‘ç¼“å­˜
            initial_cache = self.cache_manager.get_cache_entry(file_path, "translation", target_lang=target_lang)
            if initial_cache:
                logger.info(f"æ‰¾åˆ°åˆæ¬¡ç¿»è¯‘ç¼“å­˜: {Path(file_path).name} -> {target_lang}")
                initial_cache['is_user_confirmed'] = False
                return initial_cache
            
            return None
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç¿»è¯‘ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def save_translation_cache(self, file_path: str, target_lang: str, translation_data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ç¿»è¯‘ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            translation_data: ç¿»è¯‘æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç”¨æˆ·ç¡®è®¤åçš„ç¿»è¯‘
            is_user_confirmed = translation_data.get('is_user_confirmed', False)
            
            # é€‰æ‹©åˆé€‚çš„ç¼“å­˜ç±»å‹
            cache_type = "translation_confirmed" if is_user_confirmed else "translation"
            
            logger.info(f"ä¿å­˜ç¿»è¯‘ç¼“å­˜ ({cache_type}): {Path(file_path).name} -> {target_lang}")
            
            result = self.cache_manager.set_cache_entry(file_path, cache_type, translation_data, target_lang=target_lang)
            return result
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç¿»è¯‘ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def check_confirmation_cache(self, file_path: str, target_lang: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥ç”¨æˆ·ç¡®è®¤ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            
        Returns:
            ç¼“å­˜çš„ç¡®è®¤ä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            cached_data = self.cache_manager.get_cache_entry(file_path, "confirmation", target_lang=target_lang)
            if cached_data:
                logger.info(f"æ‰¾åˆ°ç¡®è®¤ä¿¡æ¯ç¼“å­˜: {Path(file_path).name} -> {target_lang}")
                return cached_data
            return None
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç¡®è®¤ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def save_confirmation_cache(self, file_path: str, target_lang: str, confirmation_data: Dict[str, Any]) -> bool:
        """
        ä¿å­˜ç”¨æˆ·ç¡®è®¤ä¿¡æ¯ç¼“å­˜
        
        Args:
            file_path: SRTæ–‡ä»¶è·¯å¾„
            target_lang: ç›®æ ‡è¯­è¨€
            confirmation_data: ç¡®è®¤æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            return self.cache_manager.set_cache_entry(file_path, "confirmation", confirmation_data, target_lang=target_lang)
        except Exception as e:
            logger.error(f"ä¿å­˜ç¡®è®¤ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def get_all_related_caches(self, file_path: str, skip_validation: bool = False) -> Dict[str, List[Dict[str, Any]]]:
        """
        è·å–ä¸æ–‡ä»¶ç›¸å…³çš„æ‰€æœ‰ç¼“å­˜
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹å“ˆå¸Œ
            skip_validation: æ˜¯å¦è·³è¿‡æ–‡ä»¶éªŒè¯ï¼ˆç”¨äºä¸´æ—¶æ–‡ä»¶åœºæ™¯ï¼‰
            
        Returns:
            æŒ‰ç±»å‹åˆ†ç»„çš„ç¼“å­˜ä¿¡æ¯
        """
        try:
            # æ”¯æŒä½¿ç”¨å†…å®¹å“ˆå¸Œç›´æ¥åŒ¹é…
            if len(file_path) == 32 and all(c in '0123456789abcdef' for c in file_path.lower()):
                # è¿™æ˜¯ä¸€ä¸ªMD5å“ˆå¸Œå€¼
                target_hash = file_path
                related_caches = []
                for entry in self.cache_manager.cache_index["cache_entries"].values():
                    if entry["file_hash"] == target_hash:
                        related_caches.append(entry)
            else:
                # åŸå§‹çš„æ–‡ä»¶è·¯å¾„åŒ¹é…
                if skip_validation:
                    # è·³è¿‡æ–‡ä»¶éªŒè¯ï¼Œç›´æ¥è¿”å›æ‰€æœ‰ç›¸å…³ç¼“å­˜
                    related_caches = []
                    for cache_key, entry in self.cache_manager.cache_index["cache_entries"].items():
                        # æ£€æŸ¥ç¼“å­˜æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        cache_data_path = self.cache_manager.cache_data_dir / f"{cache_key}.pkl"
                        if cache_data_path.exists():
                            related_caches.append(entry)
                else:
                    related_caches = self.cache_manager.find_related_caches(file_path)
            
            # æŒ‰ç±»å‹åˆ†ç»„
            grouped_caches = {}
            for cache in related_caches:
                cache_type = cache["cache_type"]
                if cache_type not in grouped_caches:
                    grouped_caches[cache_type] = []
                grouped_caches[cache_type].append(cache)
            
            return grouped_caches
        except Exception as e:
            logger.error(f"è·å–ç›¸å…³ç¼“å­˜å¤±è´¥: {e}")
            return {}
    
    def show_cache_selection_interface(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        æ˜¾ç¤ºç¼“å­˜é€‰æ‹©ç•Œé¢
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ç”¨æˆ·é€‰æ‹©çš„ç¼“å­˜æ•°æ®ï¼Œå¦‚æœç”¨æˆ·é€‰æ‹©é‡æ–°å¤„ç†åˆ™è¿”å›None
        """
        try:
            # å¯¹äºä¸´æ—¶æ–‡ä»¶ï¼Œè·³è¿‡æ–‡ä»¶éªŒè¯
            related_caches = self.get_all_related_caches(file_path, skip_validation=True)
            
            if not related_caches:
                # æ²¡æœ‰ç¼“å­˜çš„æƒ…å†µ
                st.header("ğŸ” ç¼“å­˜æ£€æŸ¥ç»“æœ")
                st.info(f"æ–‡ä»¶ `{Path(file_path).name}` æ²¡æœ‰å‘ç°ç¼“å­˜æ•°æ®")
                st.markdown("### é€‰æ‹©å¤„ç†æ–¹å¼:")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸš€ å¼€å§‹æ–°å¤„ç†", type="primary", use_container_width=True, key="start_new_processing"):
                        return {"action": "new_processing"}
                
                with col2:
                    if st.button("ğŸ”™ è¿”å›", use_container_width=True, key="back_to_upload"):
                        return {"action": "back"}
                
                return None
            
            st.header("ğŸ” å‘ç°æœ¬åœ°ç¼“å­˜")
            st.info(f"æ£€æµ‹åˆ°æ–‡ä»¶ `{Path(file_path).name}` çš„æœ¬åœ°ç¼“å­˜ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä½¿ç”¨ç¼“å­˜æˆ–é‡æ–°å¤„ç†")
            
            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            cache_stats = self.cache_manager.get_cache_statistics()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»ç¼“å­˜æ¡ç›®", cache_stats.get("total_entries", 0))
            with col2:
                st.metric("ç¼“å­˜å¤§å°", f"{cache_stats.get('cache_directory_size_mb', 0):.1f} MB")
            with col3:
                st.metric("ç›¸å…³ç¼“å­˜", len([c for caches in related_caches.values() for c in caches]))
            
            # æ˜¾ç¤ºç›¸å…³ç¼“å­˜è¯¦æƒ…
            with st.expander("ğŸ“‹ ç¼“å­˜è¯¦æƒ…"):
                for cache_type, caches in related_caches.items():
                    st.subheader(f"{self._get_cache_type_name(cache_type)} ({len(caches)} ä¸ª)")
                    
                    for i, cache in enumerate(caches):
                        created_time = cache.get("created_at", "")
                        access_count = cache.get("access_count", 0)
                        extra_params = cache.get("extra_params", {})
                        
                        # æ ¼å¼åŒ–æ—¶é—´
                        if created_time:
                            try:
                                from datetime import datetime
                                dt = datetime.fromisoformat(created_time.replace('Z', '+00:00'))
                                formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S")
                            except:
                                formatted_time = created_time
                        else:
                            formatted_time = "æœªçŸ¥"
                        
                        # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
                        cache_info = f"**ç¼“å­˜ {i+1}:** åˆ›å»ºäº {formatted_time}, è®¿é—® {access_count} æ¬¡"
                        if extra_params:
                            params_str = ", ".join([f"{k}={v}" for k, v in extra_params.items()])
                            cache_info += f", å‚æ•°: {params_str}"
                        
                        st.text(cache_info)
            
            # ç¼“å­˜é€‰æ‹©é€‰é¡¹
            st.subheader("ğŸ¯ é€‰æ‹©å¤„ç†æ–¹å¼")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„å¤„ç†æµç¨‹ç¼“å­˜
            has_complete_flow = (
                "segmentation" in related_caches and
                "translation" in related_caches and
                "confirmation" in related_caches
            )
            
            if has_complete_flow:
                st.success("âœ… å‘ç°å®Œæ•´çš„å¤„ç†æµç¨‹ç¼“å­˜")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸš€ ä½¿ç”¨å®Œæ•´ç¼“å­˜", type="primary", key="use_complete_cache"):
                        # è¿”å›å®Œæ•´çš„ç¼“å­˜æ•°æ®
                        return self._get_complete_cache_data(file_path, related_caches)
                
                with col2:
                    if st.button("ğŸ”„ é‡æ–°å¤„ç†", key="reprocess_all"):
                        return {"action": "new_processing"}
            
            # éƒ¨åˆ†ç¼“å­˜é€‰é¡¹
            st.subheader("ğŸ”§ éƒ¨åˆ†ç¼“å­˜é€‰é¡¹")
            
            cache_options = []
            
            if "segmentation" in related_caches:
                cache_options.append(("segmentation", "æ™ºèƒ½åˆ†æ®µç»“æœ"))
            
            if "translation" in related_caches:
                cache_options.append(("translation", "ç¿»è¯‘ç»“æœ"))
            
            if "confirmation" in related_caches:
                cache_options.append(("confirmation", "ç”¨æˆ·ç¡®è®¤ç»“æœ"))
            
            # æ˜¾ç¤ºéƒ¨åˆ†ç¼“å­˜é€‰é¡¹
            for cache_type, description in cache_options:
                if st.button(f"ğŸ“‹ ä½¿ç”¨{description}", key=f"use_{cache_type}_cache"):
                    logger.info(f"[show_cache_selection_interface] ç”¨æˆ·é€‰æ‹©äº† {cache_type} ç¼“å­˜")
                    return self._get_cache_data_by_type(file_path, cache_type, related_caches)
            
            # é‡æ–°å¤„ç†é€‰é¡¹
            st.markdown("---")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ†• å®Œå…¨é‡æ–°å¤„ç†", key="reprocess_complete", use_container_width=True):
                    return {"action": "new_processing"}
            
            with col2:
                if st.button("ğŸ”™ è¿”å›", key="back_to_upload", use_container_width=True):
                    return {"action": "back"}
            
            return None
            
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºç¼“å­˜é€‰æ‹©ç•Œé¢å¤±è´¥: {e}")
            return None
    
    def _get_cache_type_name(self, cache_type: str) -> str:
        """è·å–ç¼“å­˜ç±»å‹çš„ä¸­æ–‡åç§°"""
        type_names = {
            "srt_info": "SRTæ–‡ä»¶ä¿¡æ¯",
            "segmentation": "æ™ºèƒ½åˆ†æ®µ",
            "translation": "ç¿»è¯‘ç»“æœ",
            "confirmation": "ç”¨æˆ·ç¡®è®¤"
        }
        return type_names.get(cache_type, cache_type)
    
    def _get_complete_cache_data(self, file_path: str, related_caches: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """è·å–å®Œæ•´çš„ç¼“å­˜æ•°æ®"""
        try:
            complete_data = {}
            
            # è·å–åˆ†æ®µç¼“å­˜
            if "segmentation" in related_caches:
                seg_cache = related_caches["segmentation"][0]  # ä½¿ç”¨æœ€æ–°çš„
                seg_data = self.cache_manager.get_cache_entry(file_path, "segmentation", skip_validation=True)
                if seg_data:
                    complete_data["segmentation"] = seg_data
                    # å¦‚æœæœ‰ç”¨æˆ·ç¡®è®¤çš„åˆ†æ®µæ•°æ®ï¼Œä¹Ÿæ·»åŠ åˆ°è¿”å›ç»“æœä¸­
                    if "confirmed_segments" in seg_data:
                        complete_data["confirmed_segments"] = seg_data["confirmed_segments"]
            
            # è·å–ç¿»è¯‘ç¼“å­˜
            if "translation" in related_caches:
                trans_cache = related_caches["translation"][0]  # ä½¿ç”¨æœ€æ–°çš„
                target_lang = trans_cache.get("extra_params", {}).get("target_lang", "en")
                trans_data = self.cache_manager.get_cache_entry(file_path, "translation", skip_validation=True, target_lang=target_lang)
                if trans_data:
                    complete_data["translation"] = trans_data
                    complete_data["target_lang"] = target_lang
            
            # è·å–ç¡®è®¤ç¼“å­˜
            if "confirmation" in related_caches:
                conf_cache = related_caches["confirmation"][0]  # ä½¿ç”¨æœ€æ–°çš„
                target_lang = conf_cache.get("extra_params", {}).get("target_lang", "en")
                conf_data = self.cache_manager.get_cache_entry(file_path, "confirmation", skip_validation=True, target_lang=target_lang)
                if conf_data:
                    complete_data["confirmation"] = conf_data
            
            return complete_data
            
        except Exception as e:
            logger.error(f"è·å–å®Œæ•´ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _get_cache_data_by_type(self, file_path: str, cache_type: str, related_caches: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """æ ¹æ®ç±»å‹è·å–ç¼“å­˜æ•°æ®"""
        try:
            if cache_type not in related_caches:
                return {}
            
            cache_entry = related_caches[cache_type][0]  # ä½¿ç”¨æœ€æ–°çš„
            extra_params = cache_entry.get("extra_params", {})
            
            logger.info(f"[_get_cache_data_by_type] å¤„ç† {cache_type} ç¼“å­˜ï¼Œextra_params: {extra_params}")
            
            if cache_type == "segmentation":
                seg_data = self.cache_manager.get_cache_entry(file_path, "segmentation", skip_validation=True)
                if seg_data and "confirmed_segments" in seg_data:
                    # å¦‚æœæœ‰ç”¨æˆ·ç¡®è®¤çš„æ•°æ®ï¼ŒåŒæ—¶è¿”å›segmentationå’Œconfirmationæ•°æ®
                    result = {"segmentation": seg_data, "confirmed_segments": seg_data["confirmed_segments"]}
                    
                    # æ£€æŸ¥æ˜¯å¦ä¹Ÿæœ‰ç‹¬ç«‹çš„confirmationç¼“å­˜
                    conf_data = self.cache_manager.get_cache_entry(file_path, "confirmation", skip_validation=True)
                    if conf_data:
                        result["confirmation"] = conf_data
                    
                    return result
                else:
                    # å¦åˆ™è¿”å›åŸå§‹åˆ†æ®µæ•°æ®
                    return {"segmentation": seg_data}
            
            elif cache_type in ["translation", "translation_confirmed"]:
                target_lang = extra_params.get("target_lang", "en")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ç¡®è®¤åçš„ç¿»è¯‘ç¼“å­˜
                confirmed_data = None
                if "translation_confirmed" in related_caches:
                    confirmed_entry = next((entry for entry in related_caches["translation_confirmed"] 
                                          if entry.get("extra_params", {}).get("target_lang") == target_lang), None)
                    if confirmed_entry:
                        confirmed_data = self.cache_manager.get_cache_entry(file_path, "translation_confirmed", 
                                                                         skip_validation=True, target_lang=target_lang)
                
                # æ£€æŸ¥åˆæ¬¡ç¿»è¯‘ç¼“å­˜
                initial_data = None
                if "translation" in related_caches:
                    initial_entry = next((entry for entry in related_caches["translation"] 
                                        if entry.get("extra_params", {}).get("target_lang") == target_lang), None)
                    if initial_entry:
                        initial_data = self.cache_manager.get_cache_entry(file_path, "translation", 
                                                                       skip_validation=True, target_lang=target_lang)
                
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·ç¡®è®¤åçš„ç¿»è¯‘ç¼“å­˜
                result = {}
                if confirmed_data:
                    confirmed_data['is_user_confirmed'] = True
                    result["translation"] = confirmed_data
                elif initial_data:
                    initial_data['is_user_confirmed'] = False
                    result["translation"] = initial_data
                
                result["target_lang"] = target_lang
                return result
            
            elif cache_type == "confirmation":
                # ç›´æ¥ä»ç¼“å­˜ç´¢å¼•ä¸­è·å–æ•°æ®ï¼Œé¿å…é”®ç”Ÿæˆé—®é¢˜
                cache_key = cache_entry.get("cache_key")
                if cache_key:
                    # ç›´æ¥ä»ç¼“å­˜æ–‡ä»¶è¯»å–æ•°æ®
                    cache_file = self.cache_manager.cache_data_dir / f"{cache_key}.pkl"
                    if cache_file.exists():
                        import pickle
                        with open(cache_file, 'rb') as f:
                            conf_data = pickle.load(f)
                        
                        logger.info(f"[_get_cache_data_by_type] ç›´æ¥ä»æ–‡ä»¶è¯»å– confirmation ç¼“å­˜ï¼Œkeys: {list(conf_data.keys())}")
                        
                        result = {
                            "confirmation": conf_data,
                            "target_lang": extra_params.get("target_lang", "en")
                        }
                        
                        # å¦‚æœé€‰æ‹©confirmationç¼“å­˜ï¼Œä¹Ÿéœ€è¦è·å–segmentationç¼“å­˜ä¸­çš„original_segments
                        seg_data = self.cache_manager.get_cache_entry(file_path, "segmentation", skip_validation=True)
                        if seg_data:
                            result["segmentation"] = seg_data
                        
                        return result
                    else:
                        logger.error(f"[_get_cache_data_by_type] confirmation ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
                else:
                    logger.error(f"[_get_cache_data_by_type] confirmation ç¼“å­˜æ¡ç›®ç¼ºå°‘ cache_key")
                
            return {}
            
        except Exception as e:
            logger.error(f"[_get_cache_data_by_type] è·å– {cache_type} ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def clear_file_cache(self, file_path: str) -> bool:
        """
        æ¸…é™¤æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰ç¼“å­˜
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸæ¸…é™¤
        """
        try:
            related_caches = self.get_all_related_caches(file_path, skip_validation=True)
            cleared_count = 0
            
            for cache_type, caches in related_caches.items():
                for cache in caches:
                    cache_key = cache.get("cache_key")
                    if cache_key:
                        self.cache_manager._remove_cache_entry(cache_key)
                        cleared_count += 1
            
            logger.info(f"æ¸…é™¤äº† {cleared_count} ä¸ªç¼“å­˜æ¡ç›®")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…é™¤æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            return False


# å…¨å±€ç¼“å­˜é›†æˆå®ä¾‹
global_cache_integration = CacheIntegration()


def get_cache_integration() -> CacheIntegration:
    """è·å–å…¨å±€ç¼“å­˜é›†æˆå®ä¾‹"""
    return global_cache_integration 