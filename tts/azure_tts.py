"""
Azure TTSæ¨¡å— - æ”¯æŒå¾ªç¯é€¼è¿‘ç®—æ³•çš„ç²¾ç¡®è¯­é€Ÿæ§åˆ¶
ä½¿ç”¨Azure Speech Servicesè¿›è¡Œå¤šè¯­è¨€è¯­éŸ³åˆæˆï¼Œæ”¯æŒSSMLå±‚é¢çš„è¯­é€Ÿå¾®è°ƒ
"""

import azure.cognitiveservices.speech as speechsdk
from typing import List, Dict, Any, Optional, Tuple
from loguru import logger
import tempfile
import os
from pydub import AudioSegment
import io
import time
import threading
from datetime import datetime, timedelta


class AzureTTS:
    """Azure TTSè¯­éŸ³åˆæˆå™¨ - æ”¯æŒç²¾ç¡®è¯­é€Ÿæ§åˆ¶"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–Azure TTS
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        api_keys = config.get('api_keys', {})
        
        # è·å–ä¸¤ä¸ªAzure Speech keyç”¨äºæ•…éšœåˆ‡æ¢
        self.api_key_1 = api_keys.get('azure_speech_key_1')
        self.api_key_2 = api_keys.get('azure_speech_key_2')
        
        # å‘åå…¼å®¹ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªkeyé…ç½®
        if not self.api_key_1 and not self.api_key_2:
            self.api_key_1 = api_keys.get('azure_speech_key')
        
        self.region = api_keys.get('azure_speech_region')
        self.endpoint = api_keys.get('azure_speech_endpoint')
        self.tts_config = config.get('tts', {})
        
        # å½“å‰ä½¿ç”¨çš„keyç´¢å¼•ï¼ˆ0è¡¨ç¤ºkey_1ï¼Œ1è¡¨ç¤ºkey_2ï¼‰
        self.current_key_index = 0
        
        # é…ç½®è¯­éŸ³åˆæˆ
        self.speech_config = self._create_speech_config(self.api_key_1)
        
        # è®¾ç½®è¾“å‡ºæ ¼å¼ - ä½¿ç”¨48kHzè·å¾—é«˜ä¿çœŸéŸ³è´¨
        self.speech_config.set_speech_synthesis_output_format(
            speechsdk.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
        )
        
        # è¯­éŸ³æ˜ å°„
        self.voice_map = self.tts_config.get('azure', {}).get('voices', {})
        
        # åŸºç¡€è¯­éŸ³å‚æ•°
        self.base_speech_rate = self.tts_config.get('speech_rate', 1.0)
        self.pitch = self.tts_config.get('pitch', 0)
        self.volume = self.tts_config.get('volume', 90)  # è°ƒæ•´ä¸º90%ï¼Œé¿å…éŸ³é‡è¿‡å¤§
        
        # è¯·æ±‚é¢‘ç‡æ§åˆ¶ - é’ˆå¯¹å¹¶å‘ä¼˜åŒ–çš„å‚æ•°
        self.request_lock = threading.Lock()
        self.last_request_time = datetime.now()
        self.min_request_interval = 0.15  # æ¯ä¸ªè¯·æ±‚ä¹‹é—´æœ€å°é—´éš”150msï¼ˆä¸ºå¹¶å‘ä¼˜åŒ–ï¼‰
        self.request_count = 0
        self.rate_limit_reset_time = datetime.now()
        self.max_requests_per_minute = 120  # æ¯åˆ†é’Ÿæœ€å¤§è¯·æ±‚æ•°ï¼ˆä¸ºå¹¶å‘æ§åˆ¶æ›´ä¿å®ˆï¼‰
        
        # å¹¶å‘æ§åˆ¶ç›¸å…³
        self.concurrent_requests = 0  # å½“å‰å¹¶å‘è¯·æ±‚æ•°
        self.max_concurrent_requests = 8  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        
        # é”™è¯¯æ¢å¤ç›¸å…³
        self.consecutive_errors = 0
        self.max_consecutive_errors = 3
        self.error_cooldown_time = 5  # è¿ç»­é”™è¯¯åçš„å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        self.last_error_time = None
        
        # æˆæœ¬è·Ÿè¸ª
        self.api_call_count = 0
        self.total_characters = 0
        self.cost_per_character = 0.000015  # Azure TTSå®šä»·ï¼ˆçº¦$15/1Må­—ç¬¦ï¼‰
        self.session_start_time = datetime.now()
        
        # å¾ªç¯é€¼è¿‘ç›¸å…³å‚æ•°
        self.language_specific_adjustments = {
            'en': {'rate_offset': 0.08},    # è‹±è¯­ç¨å¿«
            'es': {'rate_offset': 0.06},    # è¥¿ç­ç‰™è¯­ä¸­ç­‰è°ƒæ•´
            'fr': {'rate_offset': 0.10},    # æ³•è¯­å¿«ä¸€ç‚¹
            'de': {'rate_offset': 0.05},    # å¾·è¯­è¾ƒç¨³é‡
            'ja': {'rate_offset': 0.02},    # æ—¥è¯­è¾ƒæ…¢
            'ko': {'rate_offset': 0.04}     # éŸ©è¯­ä¸­ç­‰è°ƒæ•´
        }

        # === åŠ¨æ€æ ¡å‡†ç›¸å…³ ===
        # è®°å½•å„è¯­è¨€çš„ä¼°ç®—æ ¡å‡†å› å­ï¼ˆactual / estimatedï¼‰åŠæ ·æœ¬æ•°é‡
        # é€šè¿‡æ»‘åŠ¨å¹³å‡é€æ­¥æå‡ä¼°ç®—ç²¾åº¦ï¼Œè¿›è€Œå‡å°‘TTSè°ƒç”¨æ¬¡æ•°
        self._calibration_factors: Dict[str, Dict[str, float]] = {}
    
    def _create_speech_config(self, api_key: str) -> speechsdk.SpeechConfig:
        """
        åˆ›å»ºè¯­éŸ³é…ç½®å¯¹è±¡
        
        Args:
            api_key: Azure Speech API key
            
        Returns:
            SpeechConfigå¯¹è±¡
        """
        if self.endpoint:
            # ä½¿ç”¨endpointåˆ›å»ºé…ç½®
            config = speechsdk.SpeechConfig(
                subscription=api_key,
                endpoint=self.endpoint
            )
        else:
            # ä½¿ç”¨regionåˆ›å»ºé…ç½®
            config = speechsdk.SpeechConfig(
                subscription=api_key,
                region=self.region
            )
        
        # è®¾ç½®è¶…æ—¶å‚æ•°ä»¥è§£å†³è§£ç å™¨å¯åŠ¨è¶…æ—¶é—®é¢˜
        config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, "15000")  # 15ç§’åˆå§‹é™éŸ³è¶…æ—¶
        config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, "8000")  # 8ç§’ç»“æŸé™éŸ³è¶…æ—¶
        config.set_property(speechsdk.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, "15000")  # 15ç§’è¿æ¥è¶…æ—¶
        config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, "8000")  # 8ç§’ç»“æŸè¶…æ—¶
        
        # è®¾ç½®æ›´ä¿å®ˆçš„è¿æ¥å‚æ•°ä»¥å‡å°‘è§£ç å™¨è¶…æ—¶
        config.set_property(speechsdk.PropertyId.Speech_LogFilename, "")  # ç¦ç”¨æ—¥å¿—æ–‡ä»¶
        config.set_property(speechsdk.PropertyId.SpeechServiceConnection_RecoMode, "INTERACTIVE")  # ä½¿ç”¨äº¤äº’æ¨¡å¼
        
        return config
    
    def _switch_to_backup_key(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡ç”¨key
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            if self.current_key_index == 0 and self.api_key_2:
                # åˆ‡æ¢åˆ°ç¬¬äºŒä¸ªkey
                self.current_key_index = 1
                self.speech_config = self._create_speech_config(self.api_key_2)
                # é‡æ–°è®¾ç½®è¾“å‡ºæ ¼å¼
                self.speech_config.set_speech_synthesis_output_format(
                    speechsdk.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
                )
                logger.warning("Azure Speech key 1 å¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ° key 2")
                return True
            elif self.current_key_index == 1 and self.api_key_1:
                # åˆ‡æ¢åˆ°ç¬¬ä¸€ä¸ªkey
                self.current_key_index = 0
                self.speech_config = self._create_speech_config(self.api_key_1)
                # é‡æ–°è®¾ç½®è¾“å‡ºæ ¼å¼
                self.speech_config.set_speech_synthesis_output_format(
                    speechsdk.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm
                )
                logger.warning("Azure Speech key 2 å¤±è´¥ï¼Œå·²åˆ‡æ¢åˆ° key 1")
                return True
            else:
                logger.error("æ— æ³•åˆ‡æ¢åˆ°å¤‡ç”¨keyï¼Œæˆ–å¤‡ç”¨keyä¸å­˜åœ¨")
                return False
        except Exception as e:
            logger.error(f"åˆ‡æ¢åˆ°å¤‡ç”¨keyå¤±è´¥: {str(e)}")
            return False
    
    def generate_audio_segments(self, segments: List[Dict[str, Any]], target_language: str) -> List[Dict[str, Any]]:
        """
        ç”ŸæˆéŸ³é¢‘ç‰‡æ®µï¼ˆå¹¶å‘ç‰ˆæœ¬ï¼Œæé«˜æ•ˆç‡ï¼‰
        
        Args:
            segments: ç¿»è¯‘åçš„ç‰‡æ®µåˆ—è¡¨
            target_language: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            åŒ…å«éŸ³é¢‘æ•°æ®çš„ç‰‡æ®µåˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
            
            # è·å–å¯¹åº”è¯­è¨€çš„è¯­éŸ³
            voice_name = self.voice_map.get(target_language)
            if not voice_name:
                raise ValueError(f"ä¸æ”¯æŒçš„è¯­è¨€: {target_language}")
            
            return self._generate_audio_segments_concurrent(segments, voice_name)
            
        except Exception as e:
            logger.error(f"ç”ŸæˆéŸ³é¢‘ç‰‡æ®µå¤±è´¥: {str(e)}")
            raise
    
    def _generate_audio_segments_concurrent(self, segments: List[Dict[str, Any]], voice_name: str) -> List[Dict[str, Any]]:
        """
        å¹¶å‘ç”ŸæˆéŸ³é¢‘ç‰‡æ®µ
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            voice_name: è¯­éŸ³åç§°
            
        Returns:
            éŸ³é¢‘ç‰‡æ®µåˆ—è¡¨
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import threading
        
        # æ§åˆ¶å¹¶å‘æ•°ï¼Œè€ƒè™‘APIé™åˆ¶
        max_workers = min(6, len(segments), max(2, len(segments) // 4))
        
        results_lock = threading.Lock()
        completed_count = 0
        
        logger.info(f"å¯åŠ¨å¹¶å‘éŸ³é¢‘ç”Ÿæˆ: {max_workers}ä¸ªworkerå¤„ç†{len(segments)}ä¸ªç‰‡æ®µ")
        
        def generate_single_segment(segment: Dict, index: int) -> Tuple[int, Dict]:
            """ç”Ÿæˆå•ä¸ªç‰‡æ®µçš„éŸ³é¢‘"""
            try:
                # ä½¿ç”¨é»˜è®¤è¯­é€Ÿç”Ÿæˆ
                audio_data = self._generate_single_audio(
                    segment['translated_text'],
                    voice_name,
                    self.base_speech_rate,
                    segment.get('duration', 0)
                )
                
                # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µå¯¹è±¡
                audio_segment = {
                    'id': segment['id'],
                    'start': segment['start'],
                    'end': segment['end'],
                    'original_text': segment.get('original_text', ''),
                    'translated_text': segment['translated_text'],
                    'audio_data': audio_data,
                    'duration': segment.get('duration', 0)
                }
                
                return index, audio_segment
                
            except Exception as e:
                logger.error(f"å¹¶å‘ç”Ÿæˆç‰‡æ®µ {segment['id']} éŸ³é¢‘å¤±è´¥: {str(e)}")
                # åˆ›å»ºé™éŸ³ç‰‡æ®µä½œä¸ºå¤‡é€‰
                audio_segment = self._create_silence_segment(segment)
                return index, audio_segment
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(generate_single_segment, segment, i): i
                for i, segment in enumerate(segments)
            }
            
            # æ”¶é›†ç»“æœ
            indexed_results = {}
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result_index, audio_segment = future.result()
                    indexed_results[result_index] = audio_segment
                    
                    # çº¿ç¨‹å®‰å…¨çš„è¿›åº¦æŠ¥å‘Š
                    with results_lock:
                        completed_count += 1
                        logger.info(f"éŸ³é¢‘ç”Ÿæˆè¿›åº¦: {completed_count}/{len(segments)}")
                        
                except Exception as e:
                    logger.error(f"è·å–å¹¶å‘ç»“æœå¼‚å¸¸ {index}: {e}")
                    # åˆ›å»ºé”™è¯¯ç‰‡æ®µ
                    error_segment = self._create_silence_segment(segments[index])
                    indexed_results[index] = error_segment
            
            # æŒ‰åŸå§‹é¡ºåºç»„ç»‡ç»“æœ
            audio_segments = [indexed_results[i] for i in range(len(segments))]
        
        success_count = len([seg for seg in audio_segments if seg.get('audio_data') is not None])
        logger.info(f"å¹¶å‘éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {success_count}/{len(segments)} æˆåŠŸ")
        
        return audio_segments
    
    def _generate_single_audio(self, text: str, voice_name: str, 
                              speech_rate: Optional[float] = None, 
                              target_duration: Optional[float] = None) -> AudioSegment:
        """
        ç”Ÿæˆå•ä¸ªéŸ³é¢‘ç‰‡æ®µ - æ”¯æŒç²¾ç¡®è¯­é€Ÿæ§åˆ¶å’Œæ•…éšœåˆ‡æ¢
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            voice_name: è¯­éŸ³åç§°
            speech_rate: è¯­é€Ÿå€ç‡ (1.0-1.12)
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç”¨äºè®°å½•ï¼Œä¸å½±å“ç”Ÿæˆï¼‰
            
        Returns:
            éŸ³é¢‘ç‰‡æ®µå¯¹è±¡
        """
        max_retries = 3  # å¢åŠ é‡è¯•æ¬¡æ•°
        
        for attempt in range(max_retries):
            try:
                # åº”ç”¨è¯·æ±‚é¢‘ç‡æ§åˆ¶
                self._wait_for_rate_limit()
                
                # è·Ÿè¸ªAPIè°ƒç”¨
                self._track_api_call(text)
                
                # ä½¿ç”¨ä¼ å…¥çš„è¯­é€Ÿï¼Œæˆ–é»˜è®¤è¯­é€Ÿ
                effective_rate = speech_rate if speech_rate is not None else self.base_speech_rate
                
                # æ„å»ºä¼˜åŒ–çš„SSML
                ssml = self._build_precise_ssml(text, voice_name, effective_rate)
                
                # åˆ›å»ºåˆæˆå™¨
                synthesizer = speechsdk.SpeechSynthesizer(
                    speech_config=self.speech_config,
                    audio_config=None
                )
                
                # åˆæˆè¯­éŸ³
                result = synthesizer.speak_ssml_async(ssml).get()
                
                if result is None:
                    raise Exception("è¯­éŸ³åˆæˆè¿”å›ç©ºç»“æœ")
                
                if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                    # æˆåŠŸï¼Œé‡ç½®é”™è¯¯è®¡æ•°
                    self.consecutive_errors = 0
                    self.last_error_time = None
                    
                    # é‡Šæ”¾å¹¶å‘è®¡æ•°
                    self._release_rate_limit()
                    
                    # è½¬æ¢ä¸ºAudioSegment - Raw PCMæ ¼å¼
                    # Azure TTSè¿”å›çš„æ˜¯Raw 48kHz 16-bit mono PCMæ•°æ®
                    audio_segment = AudioSegment(
                        data=result.audio_data,
                        sample_width=2,  # 16-bit = 2 bytes
                        frame_rate=48000,
                        channels=1
                    )
                    
                    actual_duration = len(audio_segment) / 1000.0
                    logger.debug(f"éŸ³é¢‘ç”ŸæˆæˆåŠŸ - è¯­é€Ÿ: {effective_rate:.3f}, æ—¶é•¿: {actual_duration:.2f}s")
                    
                    return audio_segment
                    
                else:
                    error_details = result.cancellation_details
                    error_msg = f"è¯­éŸ³åˆæˆå¤±è´¥: {result.reason}"
                    if error_details:
                        error_msg += f" - {error_details.reason}, {error_details.error_details}"
                    
                    logger.error(error_msg)
                    
                    # å¤„ç†ç‰¹å®šé”™è¯¯ç±»å‹
                    if error_details:
                        error_str = str(error_details.error_details).lower()
                        
                        # 429 Too Many Requests é”™è¯¯
                        if '429' in error_str or 'too many requests' in error_str:
                            self._handle_rate_limit_error(attempt, max_retries)
                            if attempt < max_retries - 1:
                                continue
                        
                        # è®¤è¯æˆ–é…é¢é”™è¯¯
                        elif any(keyword in error_str for keyword in ['unauthorized', 'forbidden', 'quota', 'authentication']):
                            if attempt < max_retries - 1:
                                logger.info(f"å°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨key... (ç¬¬{attempt + 1}æ¬¡å°è¯•)")
                                if self._switch_to_backup_key():
                                    continue
                        
                        # è¶…æ—¶é”™è¯¯å’Œè§£ç å™¨å¯åŠ¨é”™è¯¯
                        elif 'timeout' in error_str or 'codec decoding' in error_str:
                            self._handle_decoder_timeout_error(attempt, max_retries)
                            if attempt < max_retries - 1:
                                continue
                    
                    self._record_error()
                    # é‡Šæ”¾å¹¶å‘è®¡æ•°
                    self._release_rate_limit()
                    raise Exception(error_msg)
                    
            except Exception as e:
                self._record_error()
                # é‡Šæ”¾å¹¶å‘è®¡æ•°
                self._release_rate_limit()
                error_msg = f"ç”Ÿæˆå•ä¸ªéŸ³é¢‘å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•): {str(e)}"
                logger.error(error_msg)
                
                # å¤„ç†ç‰¹å®šé”™è¯¯ç±»å‹
                error_str = str(e).lower()
                
                # å¤„ç†429é”™è¯¯
                if '429' in error_str or 'too many requests' in error_str:
                    self._handle_rate_limit_error(attempt, max_retries)
                    if attempt < max_retries - 1:
                        continue
                
                # å¤„ç†è®¤è¯ç›¸å…³é”™è¯¯
                elif any(keyword in error_str for keyword in ['unauthorized', 'forbidden', 'quota', 'authentication']):
                    if attempt < max_retries - 1:
                        logger.info(f"å°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨key... (ç¬¬{attempt + 1}æ¬¡å°è¯•)")
                        if self._switch_to_backup_key():
                            continue
                
                # å¤„ç†è¶…æ—¶é”™è¯¯å’Œè§£ç å™¨å¯åŠ¨é”™è¯¯
                elif 'timeout' in error_str or 'codec decoding' in error_str:
                    self._handle_decoder_timeout_error(attempt, max_retries)
                    if attempt < max_retries - 1:
                        continue
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if attempt == max_retries - 1:
                    # é‡Šæ”¾å¹¶å‘è®¡æ•°
                    self._release_rate_limit()
                    raise Exception(f"æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥: {error_msg}")
        
        # é‡Šæ”¾å¹¶å‘è®¡æ•°
        self._release_rate_limit()        
        raise Exception("æ‰€æœ‰Azure Speech keyéƒ½å·²å°è¯•ï¼ŒéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
    
    def _build_precise_ssml(self, text: str, voice_name: str, speech_rate: float) -> str:
        """
        æ„å»ºç²¾ç¡®çš„SSMLæ ‡è®° - æ”¯æŒç»†ç²’åº¦è¯­é€Ÿæ§åˆ¶
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            voice_name: è¯­éŸ³åç§°
            speech_rate: è¯­é€Ÿå€ç‡
            
        Returns:
            SSMLå­—ç¬¦ä¸²
        """
        # ç¡®ä¿è¯­é€Ÿåœ¨åˆç†èŒƒå›´å†…ï¼ˆ0.95-1.15ï¼‰
        rate = max(0.95, min(1.15, speech_rate))
        
        # è½¬æ¢ä¸ºSSML rateæ ¼å¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
        if rate == 1.0:
            rate_percentage = "medium"  # ä½¿ç”¨mediumä½œä¸ºæ ‡å‡†è¯­é€Ÿ
        elif rate > 1.0:
            # å¿«äºæ ‡å‡†è¯­é€Ÿï¼Œä½¿ç”¨+ç™¾åˆ†æ¯”
            rate_percentage = f"+{int((rate - 1.0) * 100)}%"
        else:
            # æ…¢äºæ ‡å‡†è¯­é€Ÿï¼Œä½¿ç”¨-ç™¾åˆ†æ¯”
            rate_percentage = f"-{int((1.0 - rate) * 100)}%"
        
        # éŸ³è°ƒä¿æŒé»˜è®¤å€¼ï¼Œä¸è¿›è¡Œè°ƒæ•´
        pitch_value = "medium"  # ä½¿ç”¨é»˜è®¤éŸ³è°ƒ
        
        # æ„å»ºSSMLï¼Œä½¿ç”¨ç²¾ç¡®çš„è¯­éŸ³æ§åˆ¶
        ssml = f"""<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="{self._get_language_from_voice(voice_name)}">
    <voice name="{voice_name}">
        <prosody rate="{rate_percentage}" pitch="{pitch_value}" volume="{self.volume}%">
            <break time="100ms"/>
            {self._preprocess_text_for_speech(text)}
            <break time="50ms"/>
        </prosody>
    </voice>
</speak>"""
        
        logger.debug(f"ç”ŸæˆSSML - è¯­é€Ÿ: {rate_percentage}, éŸ³è°ƒ: {pitch_value}")
        return ssml
    
    def _preprocess_text_for_speech(self, text: str) -> str:
        """
        ä¸ºè¯­éŸ³åˆæˆé¢„å¤„ç†æ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬
        """
        # å¤„ç†å¸¸è§çš„å‘éŸ³é—®é¢˜
        processed_text = text
        
        # æ·»åŠ é€‚å½“çš„åœé¡¿
        processed_text = processed_text.replace('.', '.<break time="300ms"/>')
        processed_text = processed_text.replace(',', ',<break time="150ms"/>')
        processed_text = processed_text.replace(';', ';<break time="200ms"/>')
        processed_text = processed_text.replace(':', ':<break time="200ms"/>')
        
        # å¤„ç†é‡éŸ³å’Œå¼ºè°ƒ
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šçš„æ–‡æœ¬å¤„ç†é€»è¾‘
        
        return processed_text
    
    def _get_language_from_voice(self, voice_name: str) -> str:
        """
        ä»è¯­éŸ³åç§°æå–è¯­è¨€ä»£ç 
        
        Args:
            voice_name: è¯­éŸ³åç§° (å¦‚: en-US-AriaNeural)
            
        Returns:
            è¯­è¨€ä»£ç  (å¦‚: en-US)
        """
        parts = voice_name.split('-')
        if len(parts) >= 2:
            return f"{parts[0]}-{parts[1]}"
        return "en-US"  # é»˜è®¤
    
    def estimate_speech_duration(self, text: str, language: str, speech_rate: float = 1.0) -> float:
        """
        ä¼°ç®—è¯­éŸ³æ—¶é•¿ - æ›´ç²¾ç¡®çš„ä¼°ç®—ç®—æ³•
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            language: è¯­è¨€ä»£ç 
            speech_rate: è¯­é€Ÿå€ç‡
            
        Returns:
            ä¼°ç®—çš„æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        # ä¸åŒè¯­è¨€çš„åŸºç¡€æœ—è¯»é€Ÿåº¦ï¼ˆå­—ç¬¦/ç§’ï¼‰
        base_rates = {
            'en': 12.5,   # è‹±è¯­
            'es': 11.0,   # è¥¿ç­ç‰™è¯­
            'fr': 11.8,   # æ³•è¯­
            'de': 10.5,   # å¾·è¯­
            'ja': 7.5,    # æ—¥è¯­
            'ko': 8.5,    # éŸ©è¯­
            'zh': 6.8     # ä¸­æ–‡
        }
        
        base_rate = base_rates.get(language, 11.0)
        char_count = len(text)
        
        # åŸºç¡€æ—¶é—´è®¡ç®—
        base_time = char_count / base_rate
        
        # è€ƒè™‘æ ‡ç‚¹ç¬¦å·åœé¡¿
        pause_chars = '.!?ã€‚ï¼ï¼Ÿ'
        major_pause_count = sum(1 for char in text if char in pause_chars)
        minor_pause_chars = ',;ï¼Œï¼›:'
        minor_pause_count = sum(1 for char in text if char in minor_pause_chars)
        
        pause_time = major_pause_count * 0.3 + minor_pause_count * 0.15
        
        # åº”ç”¨è¯­é€Ÿè°ƒæ•´
        total_time = (base_time + pause_time) / speech_rate
        
        # æ·»åŠ èµ·å§‹å’Œç»“æŸç¼“å†²
        buffer_time = 0.2
        
        return total_time + buffer_time
    
    def estimate_audio_duration_optimized(self, text: str, language: str, speech_rate: float = 1.0) -> float:
        """
        ä¼˜åŒ–çš„è¯­éŸ³æ—¶é•¿ä¼°ç®— - åŸºäºå•è¯æ•°å’Œè¯­è¨€ç‰¹æ€§çš„ç²¾ç¡®ç®—æ³•
        ç”¨äºå‡å°‘APIè°ƒç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å¾ªç¯é€¼è¿‘ç®—æ³•ä¸­
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            language: è¯­è¨€ä»£ç 
            speech_rate: è¯­é€Ÿå€ç‡
            
        Returns:
            ä¼°ç®—çš„æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        # åŸºäºå®é™…Azure TTSçš„è¯­éŸ³ç‰¹æ€§ä¼˜åŒ–çš„ä¼°ç®—å‚æ•°ï¼ˆåŸºäºå•è¯æ•°ï¼‰
        language_params = {
            'en': {
                'words_per_second': 2.4,  # è‹±è¯­çš„å®é™…è¯­é€Ÿï¼ˆå•è¯/ç§’ï¼‰
                'pause_weight': 1.0,
                'ssml_overhead': 0.15  # SSMLå¤„ç†å¼€é”€
            },
            'es': {
                'words_per_second': 2.2,
                'pause_weight': 1.1,
                'ssml_overhead': 0.16
            },
            'fr': {
                'words_per_second': 2.3,
                'pause_weight': 1.0,
                'ssml_overhead': 0.15
            },
            'de': {
                'words_per_second': 2.1,
                'pause_weight': 1.2,
                'ssml_overhead': 0.18
            },
            'ja': {
                'words_per_second': 1.8,
                'pause_weight': 0.9,
                'ssml_overhead': 0.12
            },
            'ko': {
                'words_per_second': 1.9,
                'pause_weight': 0.95,
                'ssml_overhead': 0.14
            },
            'zh': {
                'words_per_second': 1.6,
                'pause_weight': 0.85,
                'ssml_overhead': 0.13
            }
        }
        
        # è·å–è¯­è¨€å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨è‹±è¯­
        lang_params = language_params.get(language, language_params['en'])
        
        # è®¡ç®—å•è¯æ•°ï¼ˆæ›´å‡†ç¡®çš„æ—¶é•¿ä¼°ç®—ï¼‰
        words = text.split()
        word_count = len(words)
        char_count = len(text)
        
        # è®¡ç®—åŸºç¡€æ—¶é•¿ï¼ˆåŸºäºå•è¯æ•°ï¼‰
        base_time = word_count / lang_params['words_per_second']
        
        # è®¡ç®—æ ‡ç‚¹ç¬¦å·é€ æˆçš„åœé¡¿æ—¶é—´
        major_pauses = text.count('.') + text.count('!') + text.count('?') + \
                      text.count('ã€‚') + text.count('ï¼') + text.count('ï¼Ÿ')
        minor_pauses = text.count(',') + text.count(';') + text.count(':') + \
                      text.count('ï¼Œ') + text.count('ï¼›') + text.count('ï¼š')
        
        pause_time = (major_pauses * 0.35 + minor_pauses * 0.18) * lang_params['pause_weight']
        
        # åº”ç”¨è¯­é€Ÿè°ƒæ•´
        adjusted_time = (base_time + pause_time) / speech_rate
        
        # æ·»åŠ SSMLå¤„ç†å¼€é”€
        total_time = adjusted_time + lang_params['ssml_overhead']
        
        # æ·»åŠ èµ·å§‹ç¼“å†²æ—¶é—´
        buffer_time = 0.2
        
        estimated_duration = total_time + buffer_time

        # === åº”ç”¨åŠ¨æ€æ ¡å‡†å› å­ ===
        calibration = self._calibration_factors.get(language, {}).get('factor', 1.0)
        estimated_duration *= calibration

        logger.debug(f"æ—¶é•¿ä¼°ç®—: æ–‡æœ¬={word_count}å•è¯({char_count}å­—ç¬¦), åŸºç¡€={base_time:.2f}s, "
                    f"åœé¡¿={pause_time:.2f}s, è¯­é€Ÿ={speech_rate:.2f}, "
                    f"æ ¡å‡†å› å­={calibration:.3f}, é¢„ä¼°={estimated_duration:.2f}s")
        
        return estimated_duration
    
    def estimate_optimal_speech_rate(self, text: str, language: str, target_duration: float, 
                                   min_rate: float = 0.95, max_rate: float = 1.15) -> float:
        """
        ä¼°ç®—è¾¾åˆ°ç›®æ ‡æ—¶é•¿æ‰€éœ€çš„æœ€ä¼˜è¯­é€Ÿ
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            language: è¯­è¨€ä»£ç 
            target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
            min_rate: æœ€å°è¯­é€Ÿ
            max_rate: æœ€å¤§è¯­é€Ÿ
            
        Returns:
            æœ€ä¼˜è¯­é€Ÿå€ç‡
        """
        # ä½¿ç”¨æ ‡å‡†è¯­é€Ÿä¼°ç®—åŸºç¡€æ—¶é•¿
        base_duration = self.estimate_audio_duration_optimized(text, language, 1.0)
        
        # è®¡ç®—æ‰€éœ€è¯­é€Ÿ
        required_rate = base_duration / target_duration
        
        # é™åˆ¶åœ¨å…è®¸èŒƒå›´å†…
        optimal_rate = max(min_rate, min(required_rate, max_rate))
        
        logger.debug(f"è¯­é€Ÿä¼°ç®—: åŸºç¡€æ—¶é•¿={base_duration:.2f}s, ç›®æ ‡æ—¶é•¿={target_duration:.2f}s, "
                    f"æ‰€éœ€è¯­é€Ÿ={required_rate:.3f}, æœ€ä¼˜è¯­é€Ÿ={optimal_rate:.3f}")
        
        return optimal_rate
    
    def _create_silence_segment(self, segment: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ›å»ºé™éŸ³ç‰‡æ®µ
        
        Args:
            segment: åŸå§‹ç‰‡æ®µä¿¡æ¯
            
        Returns:
            é™éŸ³éŸ³é¢‘ç‰‡æ®µ
        """
        duration_ms = int(segment.get('duration', 1.0) * 1000)
        silence = AudioSegment.silent(duration=duration_ms)
        
        return {
            'id': segment['id'],
            'start': segment['start'],
            'end': segment['end'],
            'original_text': segment.get('original_text', ''),
            'translated_text': segment.get('translated_text', ''),
            'audio_data': silence,
            'duration': segment.get('duration', 0)
        }
    
    def get_current_key_info(self) -> dict:
        """
        è·å–å½“å‰ä½¿ç”¨çš„keyä¿¡æ¯
        
        Returns:
            åŒ…å«å½“å‰keyä¿¡æ¯çš„å­—å…¸
        """
        current_key = self.api_key_1 if self.current_key_index == 0 else self.api_key_2
        return {
            'current_key_index': self.current_key_index,
            'current_key': current_key[:8] + '...' if current_key else None,
            'has_backup_key': bool(self.api_key_2 if self.current_key_index == 0 else self.api_key_1),
            'region': self.region,
            'endpoint': self.endpoint
        }
    
    def test_voice_synthesis(self, text: str = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•", voice_name: Optional[str] = None) -> bool:
        """
        æµ‹è¯•è¯­éŸ³åˆæˆåŠŸèƒ½ï¼Œæ”¯æŒæ•…éšœåˆ‡æ¢
        
        Args:
            text: æµ‹è¯•æ–‡æœ¬
            voice_name: è¯­éŸ³åç§°
            
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        try:
            if not voice_name:
                voice_name = list(self.voice_map.values())[0]
            
            # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„keyä¿¡æ¯
            key_info = self.get_current_key_info()
            logger.info(f"å½“å‰ä½¿ç”¨key {key_info['current_key_index'] + 1}: {key_info['current_key']}")
            
            # ä½¿ç”¨åŸºç¡€è¯­é€Ÿè¿›è¡Œæµ‹è¯•
            if voice_name is None:
                voice_name = list(self.voice_map.values())[0]
            test_audio = self._generate_single_audio(text, voice_name, 1.0)  # type: ignore
            
            logger.info(f"è¯­éŸ³åˆæˆæµ‹è¯•æˆåŠŸ - æ—¶é•¿: {len(test_audio)/1000:.2f}s")
            return True
                
        except Exception as e:
            logger.error(f"è¯­éŸ³åˆæˆæµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def get_available_voices(self, language: Optional[str] = None) -> List[str]:
        """
        è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
        
        Args:
            language: è¯­è¨€ä»£ç ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å¯ç”¨è¯­éŸ³åˆ—è¡¨
        """
        if language:
            return [voice for lang, voice in self.voice_map.items() if lang == language]
        else:
            return list(self.voice_map.values())
    
    def get_optimal_rate_for_language(self, language: str, base_rate: float = 1.0) -> float:
        """
        è·å–è¯­è¨€çš„æœ€ä¼˜è¯­é€Ÿ
        
        Args:
            language: è¯­è¨€ä»£ç 
            base_rate: åŸºç¡€è¯­é€Ÿ
            
        Returns:
            æœ€ä¼˜è¯­é€Ÿ
        """
        # è·å–è¯­è¨€ç‰¹å®šçš„è°ƒæ•´ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        rate_offset = self.language_specific_adjustments.get(language, {}).get('rate_offset', 0)
        
        optimal_rate = base_rate + rate_offset
        # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…ï¼š0.8 - 1.15
        return max(0.8, min(1.15, optimal_rate))
    
    def create_synthesis_report(self, segments: List[Dict[str, Any]]) -> str:
        """
        åˆ›å»ºè¯­éŸ³åˆæˆæŠ¥å‘Š
        
        Args:
            segments: å¤„ç†è¿‡çš„ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        if not segments:
            return "æ— éŸ³é¢‘ç‰‡æ®µæ•°æ®"
        
        total_segments = len(segments)
        total_duration = sum(seg.get('actual_duration', seg.get('duration', 0)) for seg in segments)
        
        # ç»Ÿè®¡è¯­é€Ÿåˆ†å¸ƒï¼ˆä¼˜åŒ–ï¼šä¸€æ¬¡éå†æ”¶é›†æ‰€æœ‰éœ€è¦çš„æ•°æ®ï¼‰
        speeds = []
        quality_counts = {'excellent': 0, 'good': 0, 'short_text': 0, 'long_text': 0, 'fallback': 0}
        
        for seg in segments:
            speed = seg.get('final_speed', 1.0)
            speeds.append(speed)
            
            quality = seg.get('sync_quality', 'unknown')
            if quality in quality_counts:
                quality_counts[quality] += 1
        
        # è®¡ç®—é€Ÿåº¦ç»Ÿè®¡
        avg_speed = sum(speeds) / len(speeds)
        min_speed = min(speeds)
        max_speed = max(speeds)
        
        # è¯­é€Ÿåˆ†å¸ƒç»Ÿè®¡ï¼ˆæ–°çš„èŒƒå›´ï¼š0.95-1.15ï¼‰
        speed_distribution = {
            '0.95-1.00': sum(1 for s in speeds if 0.95 <= s < 1.00),
            '1.00-1.05': sum(1 for s in speeds if 1.00 <= s < 1.05),
            '1.05-1.10': sum(1 for s in speeds if 1.05 <= s < 1.10),
            '1.10-1.15': sum(1 for s in speeds if 1.10 <= s <= 1.15)
        }
        
        report = f"""Azure TTSè¯­éŸ³åˆæˆæŠ¥å‘Š
========================

åŸºæœ¬ä¿¡æ¯:
  - æ€»ç‰‡æ®µæ•°: {total_segments}
  - æ€»éŸ³é¢‘æ—¶é•¿: {total_duration:.1f}ç§’
  - å¹³å‡è¯­é€Ÿ: {avg_speed:.3f}
  - è¯­é€ŸèŒƒå›´: {min_speed:.3f} - {max_speed:.3f}

è´¨é‡åˆ†æ:
  - ä¼˜ç§€ç‰‡æ®µ: {quality_counts['excellent']} ({quality_counts['excellent']/total_segments*100:.1f}%)
  - è‰¯å¥½ç‰‡æ®µ: {quality_counts['good']} ({quality_counts['good']/total_segments*100:.1f}%)
  - çŸ­æ–‡æœ¬ç‰‡æ®µ: {quality_counts['short_text']} ({quality_counts['short_text']/total_segments*100:.1f}%)
  - é•¿æ–‡æœ¬ç‰‡æ®µ: {quality_counts['long_text']} ({quality_counts['long_text']/total_segments*100:.1f}%)
  - å…œåº•ç‰‡æ®µ: {quality_counts['fallback']} ({quality_counts['fallback']/total_segments*100:.1f}%)

è¯­é€Ÿåˆ†å¸ƒ:
  - 0.95-1.00: {speed_distribution['0.95-1.00']} ç‰‡æ®µ
  - 1.00-1.05: {speed_distribution['1.00-1.05']} ç‰‡æ®µ
  - 1.05-1.10: {speed_distribution['1.05-1.10']} ç‰‡æ®µ
  - 1.10-1.15: {speed_distribution['1.10-1.15']} ç‰‡æ®µ
"""
        
        return report

    def _track_api_call(self, text: str):
        """
        è·Ÿè¸ªAPIè°ƒç”¨æ¬¡æ•°å’Œæˆæœ¬
        
        Args:
            text: åˆæˆçš„æ–‡æœ¬
        """
        self.api_call_count += 1
        self.total_characters += len(text)
        logger.debug(f"APIè°ƒç”¨ç»Ÿè®¡: ç¬¬{self.api_call_count}æ¬¡è°ƒç”¨, ç´¯è®¡å­—ç¬¦æ•°: {self.total_characters}")
    
    def get_cost_summary(self) -> Dict[str, Any]:
        """
        è·å–æˆæœ¬æ‘˜è¦
        
        Returns:
            åŒ…å«æˆæœ¬ä¿¡æ¯çš„å­—å…¸
        """
        elapsed_time = (datetime.now() - self.session_start_time).total_seconds()
        estimated_cost = self.total_characters * self.cost_per_character
        
        return {
            'api_calls': self.api_call_count,
            'total_characters': self.total_characters,
            'estimated_cost_usd': estimated_cost,
            'session_duration_seconds': elapsed_time,
            'avg_calls_per_minute': (self.api_call_count / elapsed_time * 60) if elapsed_time > 0 else 0,
            'avg_characters_per_call': (self.total_characters / self.api_call_count) if self.api_call_count > 0 else 0
        }
    
    def print_cost_report(self):
        """
        æ‰“å°æˆæœ¬æŠ¥å‘Š
        """
        summary = self.get_cost_summary()
        
        print("\n" + "="*60)
        print("ğŸ”¥ AZURE TTS æˆæœ¬æŠ¥å‘Š")
        print("="*60)
        print(f"ğŸ“Š APIè°ƒç”¨æ¬¡æ•°: {summary['api_calls']}")
        print(f"ğŸ“ æ€»å­—ç¬¦æ•°: {summary['total_characters']:,}")
        print(f"ğŸ’° ä¼°è®¡æˆæœ¬: ${summary['estimated_cost_usd']:.4f}")
        print(f"â±ï¸  ä¼šè¯æ—¶é•¿: {summary['session_duration_seconds']:.1f}ç§’")
        print(f"ğŸ“ˆ å¹³å‡è°ƒç”¨é¢‘ç‡: {summary['avg_calls_per_minute']:.1f}æ¬¡/åˆ†é’Ÿ")
        print(f"ğŸ“‹ å¹³å‡å­—ç¬¦æ•°/è°ƒç”¨: {summary['avg_characters_per_call']:.1f}")
        print("="*60)
        
        # æˆæœ¬ä¼˜åŒ–å»ºè®®
        if summary['api_calls'] > 50:
            print("ğŸ’¡ æˆæœ¬ä¼˜åŒ–å»ºè®®:")
            print("  â€¢ å¯ç”¨æˆæœ¬ä¼˜åŒ–æ¨¡å¼å¯å‡å°‘60-80%çš„APIè°ƒç”¨")
            print("  â€¢ ä½¿ç”¨ä¼°ç®—æ–¹æ³•é¢„ç­›é€‰å¯é¿å…ä¸å¿…è¦çš„APIè°ƒç”¨")
            print("  â€¢ è€ƒè™‘æ‰¹é‡å¤„ç†è¾ƒçŸ­çš„æ–‡æœ¬ç‰‡æ®µ")
        print("="*60 + "\n")

    def _wait_for_rate_limit(self):
        """
        ç­‰å¾…æ»¡è¶³è¯·æ±‚é¢‘ç‡é™åˆ¶ - æ”¯æŒå¹¶å‘æ§åˆ¶
        """
        with self.request_lock:
            current_time = datetime.now()
            
            # æ£€æŸ¥å¹¶å‘æ•°é™åˆ¶
            while self.concurrent_requests >= self.max_concurrent_requests:
                logger.debug(f"è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°({self.max_concurrent_requests})ï¼Œç­‰å¾…...")
                time.sleep(0.05)  # çŸ­æš‚ç­‰å¾…
                current_time = datetime.now()
            
            # é‡ç½®åˆ†é’Ÿè®¡æ•°å™¨
            if current_time - self.rate_limit_reset_time >= timedelta(minutes=1):
                self.request_count = 0
                self.rate_limit_reset_time = current_time
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶
            if self.request_count >= self.max_requests_per_minute:
                wait_time = 60 - (current_time - self.rate_limit_reset_time).seconds
                if wait_time > 0:
                    logger.warning(f"è¾¾åˆ°æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time.sleep(wait_time)
                    self.request_count = 0
                    self.rate_limit_reset_time = datetime.now()
            
            # æ£€æŸ¥è¯·æ±‚é—´éš”ï¼ˆå¯¹å¹¶å‘è¯·æ±‚ç¨å¾®æ”¾å®½ï¼‰
            time_since_last = (current_time - self.last_request_time).total_seconds()
            min_interval = self.min_request_interval / max(1, self.concurrent_requests)
            if time_since_last < min_interval:
                wait_time = min_interval - time_since_last
                time.sleep(wait_time)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨é”™è¯¯å†·å´æœŸ
            if (self.last_error_time and 
                self.consecutive_errors >= self.max_consecutive_errors):
                cooldown_elapsed = (current_time - self.last_error_time).total_seconds()
                if cooldown_elapsed < self.error_cooldown_time:
                    wait_time = self.error_cooldown_time - cooldown_elapsed
                    logger.warning(f"é”™è¯¯å†·å´æœŸï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
                    time.sleep(wait_time)
                    self.consecutive_errors = 0
            
            # æ›´æ–°è®¡æ•°å™¨
            self.concurrent_requests += 1
            self.last_request_time = datetime.now()
            self.request_count += 1
    
    def _release_rate_limit(self):
        """
        é‡Šæ”¾å¹¶å‘è®¡æ•°
        """
        with self.request_lock:
            self.concurrent_requests = max(0, self.concurrent_requests - 1)
    
    def _record_error(self):
        """
        è®°å½•é”™è¯¯å‘ç”Ÿ
        """
        self.consecutive_errors += 1
        self.last_error_time = datetime.now()
        logger.debug(f"è¿ç»­é”™è¯¯æ¬¡æ•°: {self.consecutive_errors}")
    
    def _handle_rate_limit_error(self, attempt: int, max_retries: int):
        """
        å¤„ç†429é™æµé”™è¯¯
        """
        base_wait = 2 ** attempt  # æŒ‡æ•°é€€é¿
        jitter = 0.1 * base_wait  # æ·»åŠ éšæœºæ€§
        wait_time = base_wait + jitter
        
        logger.warning(f"é‡åˆ°429é”™è¯¯ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• (ç¬¬{attempt + 1}/{max_retries}æ¬¡)")
        time.sleep(wait_time)
    
    def _handle_timeout_error(self, attempt: int, max_retries: int):
        """
        å¤„ç†è¶…æ—¶é”™è¯¯
        """
        wait_time = 1.0 + (attempt * 0.5)  # æ¸è¿›å¼ç­‰å¾…
        logger.warning(f"é‡åˆ°è¶…æ—¶é”™è¯¯ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• (ç¬¬{attempt + 1}/{max_retries}æ¬¡)")
        time.sleep(wait_time)
    
    def _handle_decoder_timeout_error(self, attempt: int, max_retries: int):
        """
        å¤„ç†è§£ç å™¨å¯åŠ¨è¶…æ—¶é”™è¯¯ - å¢å¼ºç‰ˆæœ¬
        """
        # å¯¹äºè§£ç å™¨å¯åŠ¨è¶…æ—¶ï¼Œä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´å’Œæ›´ä¿å®ˆçš„ç­–ç•¥
        if attempt == 0:
            # ç¬¬ä¸€æ¬¡é‡åˆ°è§£ç å™¨è¶…æ—¶ï¼Œç­‰å¾…è¾ƒé•¿æ—¶é—´
            base_wait = 5.0
        elif attempt == 1:
            # ç¬¬äºŒæ¬¡ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
            base_wait = 8.0
        else:
            # åç»­å°è¯•ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
            base_wait = 10.0 + (attempt * 2.0)
        
        jitter = 0.3 * base_wait  # 30%çš„éšæœºå»¶è¿Ÿ
        wait_time = base_wait + jitter
        
        logger.warning(f"é‡åˆ°è§£ç å™¨å¯åŠ¨è¶…æ—¶é”™è¯¯ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• (ç¬¬{attempt + 1}/{max_retries}æ¬¡)")
        
        # åœ¨ç­‰å¾…æœŸé—´ï¼Œå°è¯•æ¸…ç†å¯èƒ½çš„èµ„æº
        try:
            import gc
            gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        except:
            pass
        
        time.sleep(wait_time) 

    def update_calibration(self, language: str, estimated_duration: float, actual_duration: float):
        """æ ¹æ®ä¸€æ¬¡çœŸå®åˆæˆç»“æœæ›´æ–°æŒ‡å®šè¯­è¨€çš„æ ¡å‡†å› å­

        Args:
            language: è¯­è¨€ä»£ç  (å¦‚ 'en')
            estimated_duration: æœ¬æ¬¡ä¼°ç®—çš„æ—¶é•¿ï¼ˆç§’ï¼‰
            actual_duration: å®é™…åˆæˆåçš„æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            if estimated_duration <= 0 or actual_duration <= 0:
                return

            factor = actual_duration / estimated_duration
            entry = self._calibration_factors.get(language)

            if entry is None:
                entry = {'factor': factor, 'samples': 1}
            else:
                # æŒ‡æ•°æ»‘åŠ¨å¹³å‡ï¼Œæœ€è¿‘æ ·æœ¬æƒé‡æ›´é«˜ (alpha = 0.3)
                alpha = 0.3
                entry['factor'] = entry['factor'] * (1 - alpha) + factor * alpha
                entry['samples'] += 1

            self._calibration_factors[language] = entry
            logger.debug(f"æ›´æ–°æ ¡å‡†å› å­: {language} -> {entry['factor']:.3f} (samples={entry['samples']})")
        except Exception as e:
            logger.warning(f"æ›´æ–°æ ¡å‡†å› å­å¤±è´¥: {str(e)}")

    def get_calibration_factor(self, language: str) -> float:
        """è·å–æŒ‡å®šè¯­è¨€çš„å½“å‰æ ¡å‡†å› å­"""
        return self._calibration_factors.get(language, {}).get('factor', 1.0) 

    def synthesize_speech_optimized(self, text: str, language: str, speech_rate: float, file_prefix: str = "tts_segment") -> str:
        """
        å…¼å®¹sync_managerçš„éŸ³é¢‘åˆæˆæ–¹æ³•ï¼Œè‡ªåŠ¨é€‰æ‹©voiceå¹¶ä¿å­˜ä¸ºwavæ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„
        Args:
            text: åˆæˆæ–‡æœ¬
            language: ç›®æ ‡è¯­è¨€ä»£ç 
            speech_rate: è¯­é€Ÿå€ç‡
            file_prefix: æ–‡ä»¶åå‰ç¼€
        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        voice_name = self.voice_map.get(language)
        if not voice_name:
            raise ValueError(f"æœªé…ç½®è¯­è¨€ {language} çš„voice")
        audio_segment = self._generate_single_audio(text, voice_name, speech_rate)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav", prefix=file_prefix + "_") as f:
            audio_segment.export(f.name, format="wav")
            file_path = f.name
        return file_path 

    def get_audio_duration(self, audio_file_path: str) -> float:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿
        
        Args:
            audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            from pydub import AudioSegment
            audio = AudioSegment.from_wav(audio_file_path)
            duration_seconds = len(audio) / 1000.0
            return duration_seconds
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0 